{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "URL = 'http://www.nationalgeographic.com.cn/animals/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### find list of image elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://image.ngchina.com.cn/2018/0828/20180828072324430.jpg',\n",
       " 'http://image.ngchina.com.cn/2018/0828/20180828105855611.jpg',\n",
       " 'http://image.ngchina.com.cn/2018/0827/20180827051015964.jpg',\n",
       " 'http://image.ngchina.com.cn/2018/0824/20180824113210425.jpg',\n",
       " 'http://image.ngchina.com.cn/2018/0822/20180822052553583.jpg',\n",
       " 'http://image.ngchina.com.cn/2018/0822/20180822113723979.jpg']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = requests.get(URL).text\n",
    "soup = BeautifulSoup(html, 'lxml')\n",
    "img_ul_elements = soup.find_all('ul', {'class': 'img_list'})\n",
    "img_urls = []\n",
    "for img_ul_ele in img_ul_elements:\n",
    "    img_elements = img_ul_ele.find_all('img')\n",
    "    for img_ele in img_elements:\n",
    "        img_urls.append(img_ele['src'])\n",
    "img_urls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### donwload the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Downloaded]  20180822113723979.jpg\n",
      "[Downloaded]  20180822052553583.jpg\n",
      "[Downloaded]  20180824113210425.jpg\n",
      "[Downloaded]  20180827051015964.jpg\n",
      "[Downloaded]  20180828105855611.jpg\n",
      "[Downloaded]  20180828072324430.jpg\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "img_save_path = './imgs/national-geographic/'\n",
    "os.makedirs(img_save_path, exist_ok=True)\n",
    "\n",
    "while img_urls:\n",
    "    img_url = img_urls.pop()\n",
    "    r = requests.get(img_url, stream=True)\n",
    "    img_name = img_url.split('/')[-1]\n",
    "    with open(img_save_path + img_name, 'wb') as f:\n",
    "        for chunk in r.iter_content(chunk_size=128):\n",
    "            f.write(chunk)\n",
    "            \n",
    "        print('[Downloaded] ', img_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
